{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoboCall Mitigation Database\n",
    "- Original file: rmd-original.csv\n",
    "    - Contains details of thousands of providers\n",
    "    - Details inculde business information such as FRN, Company Name, Contact Details, Person responsible for S/S deployment\n",
    "    - Detials also include the level of S/S implementation - Yes / No / Partial\n",
    "- Task of this Jupyter notebook is to filter out duplicates and NULL entries and extract US providers' S/S implementation details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section contains functions that are used to manipulate the CSV\n",
    "- add_index_column\n",
    "- extract_columns\n",
    "- remove_newlines_inside_rows\n",
    "- remove_duplicates_based_on_2_fields\n",
    "- filter_by_country\n",
    "- remove_null_rows\n",
    "- update_implementation_field\n",
    "- sort_by_business_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin add_index_column\n",
    "# Takes a CSV file and inserts an index column at the beginning and outputs a new CSV file\n",
    "def add_index_column(input_file, output_file):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, dtype=str)\n",
    "        df.insert(0, 'index', range(1, len(df) + 1))\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Indexed CSV saved to {output_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End add_index_column\n",
    "\n",
    "### Begin extract_columns\n",
    "# Takes a CSV file and column names as input an outputs a new CSV file containing only those columns specified\n",
    "def extract_columns(input_file, output_file, fields):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, usecols=fields, dtype=str)\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Extracted columns  CSV saved to {output_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End extract_columns\n",
    "\n",
    "### Begin remove_newlines_inside_rows\n",
    "# Takes a CSV file and column names as input and removes any new lines present in any of the column entries. Outputs a new CSV file.\n",
    "def remove_newlines_inside_rows(file_path, columns_to_process, output_path):\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "\n",
    "        # Function to replace newlines within double quotes\n",
    "        def replace_newlines_in_quotes(text):\n",
    "            try:\n",
    "                text = text.replace(\"\\n\", ' ')\n",
    "                text = text.replace(\"\\r\", ' ')\n",
    "            except:\n",
    "                None\n",
    "            return text\n",
    "\n",
    "        # Process the specified columns\n",
    "        for column in columns_to_process:\n",
    "            if column in df.columns:\n",
    "                df[column] = df[column].apply(replace_newlines_in_quotes)\n",
    "\n",
    "        # Save the updated CSV\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"No newlines CSV saved to {output_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End remove_newlines_inside_rows\n",
    "\n",
    "### Begin remove_duplicates_based_on_2_fields\n",
    "# Reads a CSV file, removes duplicates based on two specified fields, and writes the result to a new file.\n",
    "def remove_duplicates_based_on_2_fields(csv_file, field1, field2, output_file):\n",
    "    # Load the CSV file\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Separate rows with NaN in the specified fields\n",
    "        nan_rows = df[df[[field1, field2]].isna().any(axis=1)]\n",
    "        \n",
    "        # Identify rows without NaN in the specified fields\n",
    "        valid_rows = df.dropna(subset=[field1, field2])\n",
    "        \n",
    "        # Identify duplicates in valid rows\n",
    "        duplicates = valid_rows.duplicated(subset=[field1, field2], keep=False)\n",
    "        \n",
    "        # Filter unique rows from valid rows (first occurrence of duplicates + rows that are not duplicates)\n",
    "        deduplicated_valid_rows = valid_rows[~duplicates | (valid_rows.duplicated(subset=[field1, field2], keep='first'))]\n",
    "        \n",
    "        # Combine deduplicated valid rows with rows that have NaN\n",
    "        final_df = pd.concat([deduplicated_valid_rows, nan_rows], ignore_index=True)\n",
    "        \n",
    "        # Save the result to a new CSV file\n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"Deduplicated data based on {field1} and {field2} has been saved to {output_file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End remove_duplicates_based_on_2_fields\n",
    "\n",
    "### Begin filter_by_country\n",
    "# Extract out providers based on country\n",
    "def filter_by_country(input_file, country, output_file):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, dtype=str)\n",
    "        filtered_df = df[df['country'] == country]\n",
    "        filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Country filtered CSV saved to {output_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End filter_by_country\n",
    "\n",
    "### Begin remove_null_rows\n",
    "# If any of the fields provided are null then, that row is deleted\n",
    "def remove_null_rows(input_file, fields, output_file):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, dtype=str)\n",
    "        filtered_df = df.dropna(subset=fields)\n",
    "        filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Removed null rows CSV saved to {output_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End remove_null_rows\n",
    "\n",
    "### Begin update_implementation_field\n",
    "# Update the implementation field according to the map\n",
    "def update_implementation_field(input_file, output_file):\n",
    "    mapping = {\n",
    "        \"Complete STIR/SHAKEN Implementation\": \"Yes\",\n",
    "        \"Partial STIR/SHAKEN Implementation - Performing Robocall Mitigation\": \"Partial\",\n",
    "        \"No STIR/SHAKEN Implementation - Performing Robocall Mitigation\": \"No\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_file, dtype=str)\n",
    "        df['implementation'] = df['implementation'].map(mapping).fillna(df['implementation'])\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Updated implementation field CSV saved to {output_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End update_implementation_field\n",
    "\n",
    "### Begin sort_by_business_name\n",
    "# Sort alphabetically based on business_name\n",
    "def sort_by_business_name(input_file, output_file):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, dtype=str)\n",
    "        df = df.sort_values(by=\"business_name\", ascending=True)\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Sorted CSV saved to {output_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End sort_by_business_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section contains functions that are used to display the requested field from the CSV\n",
    "- print_duplicated_rows\n",
    "- print_duplicated_rows_2_fields\n",
    "- print_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin print_duplicated_rows\n",
    "# Takes a CSV file as input and prints duplicates in each column\n",
    "def print_duplicated_rows(file_path):\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "\n",
    "        # Identify duplicates in each column\n",
    "        for column in df.columns:\n",
    "            duplicates = df[column][df[column].duplicated()]\n",
    "            if not duplicates.empty:\n",
    "                print(f\"Duplicates in column '{column}':\")\n",
    "                print(duplicates)\n",
    "                print()\n",
    "            else:\n",
    "                print(f\"No duplicates found in column '{column}'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End print_duplicated_rows\n",
    "\n",
    "### Begin print_duplicated_rows_2_fields\n",
    "# takes a CSV file and two field names as input, then selects and prints rows where both field entries are duplicated\n",
    "def print_duplicated_rows_2_fields(input_csv, field1, field2):\n",
    "    # Load the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_csv}' was not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Check if the specified fields exist\n",
    "    if field1 not in df.columns or field2 not in df.columns:\n",
    "        print(f\"Error: One or both fields '{field1}' and '{field2}' do not exist in the CSV file.\")\n",
    "        return\n",
    "\n",
    "    # Identify rows where both fields have duplicate values\n",
    "    duplicated_rows = df[df.duplicated(subset=[field1, field2], keep=False)]\n",
    "    \n",
    "    # Group by the specified fields and sort the results\n",
    "    grouped_duplicates = duplicated_rows.sort_values(by=[field1, field2])\n",
    "    \n",
    "    # Print the grouped duplicate rows (only the specified fields)\n",
    "    if grouped_duplicates.empty:\n",
    "        print(\"No rows with duplicate values in both fields were found.\")\n",
    "    else:\n",
    "        print(\"Grouped duplicate rows with specified fields:\")\n",
    "        print(grouped_duplicates[['index', field1, field2]].to_string(index=False))\n",
    "### End print_duplicated_rows_2_fields\n",
    "\n",
    "### Begin \n",
    "# Print stats of the final CSV\n",
    "def print_stats(input_csv):\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv, dtype=str)\n",
    "\n",
    "        count_total_providers = df.shape[0]\n",
    "\n",
    "        count_impl_yes = df[\"implementation\"].eq(\"Yes\").sum()\n",
    "        count_impl_partial = df[\"implementation\"].eq(\"Partial\").sum()\n",
    "        count_impl_no = df[\"implementation\"].eq(\"No\").sum()\n",
    "\n",
    "        count_vo_pwd = df[\"voice_service_provider_choice\"].eq(\"Yes\").sum()\n",
    "        count_gw_pwd = df[\"gateway_provider_choice\"].eq(\"Yes\").sum()\n",
    "        count_int_pwd = df[\"intermediate_provider_choice\"].eq(\"Yes\").sum()\n",
    "\n",
    "        print(\"CSV stats:\")\n",
    "        print(f\"Total providers = {count_total_providers}\")\n",
    "\n",
    "        print(f\"Full S/S implementation = {count_impl_yes}\")\n",
    "        print(f\"Partial S/S implementation = {count_impl_partial}\")\n",
    "        print(f\"No S/S implementation = {count_impl_no}\")\n",
    "\n",
    "        print(f\"Count of voice providers = {count_gw_pwd}\")\n",
    "        print(f\"Count of gateway providers = {count_vo_pwd}\")\n",
    "        print(f\"Count of intermediate providers = {count_int_pwd}\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_csv}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed CSV saved to csv/rmd-1-indexed.csv\n",
      "No newlines CSV saved to csv/rmd-2-nonl.csv\n",
      "Country filtered CSV saved to csv/rmd-3-country.csv\n",
      "Removed null rows CSV saved to csv/rmd-4-nonull.csv\n",
      "Updated implementation field CSV saved to csv/rmd-5-updimpl.csv\n",
      "Deduplicated data based on business_name and business_address has been saved to csv/rmd-6-dedup2F.csv.\n",
      "Deduplicated data based on business_name and contact_business_address has been saved to csv/rmd-6-dedup2F.csv.\n",
      "Deduplicated data based on business_name and frn has been saved to csv/rmd-6-dedup2F.csv.\n",
      "Sorted CSV saved to csv/rmd-7-sort.csv\n"
     ]
    }
   ],
   "source": [
    "# Filenames\n",
    "og_csv = \"csv/rmd-original.csv\"\n",
    "indexed_csv = \"csv/rmd-1-indexed.csv\"\n",
    "nonl_csv = \"csv/rmd-2-nonl.csv\"\n",
    "country_csv = \"csv/rmd-3-country.csv\"\n",
    "nonull_csv = \"csv/rmd-4-nonull.csv\"\n",
    "upd_impl_csv = \"csv/rmd-5-updimpl.csv\"\n",
    "dedup_2F_csv = \"csv/rmd-6-dedup2F.csv\"\n",
    "sort_csv = \"csv/rmd-7-sort.csv\"\n",
    "final_csv = \"csv/rmd-final.csv\"\n",
    "\n",
    "# Func args\n",
    "nonl_cols = [\"business_address\", \"other_dba_names\", \"previous_dba_names\", \"contact_business_address\", \"other_frns\"]\n",
    "country = \"United States of America\"\n",
    "nonull_cols = [\"implementation\", \"frn\", \"business_name\"]\n",
    "\n",
    "# Adding index field to the original csv\n",
    "add_index_column(og_csv, indexed_csv)\n",
    "\n",
    "# Remove new lines in business_address and contact_business_address fields\n",
    "remove_newlines_inside_rows(indexed_csv, nonl_cols, nonl_csv)\n",
    "\n",
    "# Filter by country\n",
    "filter_by_country(nonl_csv, country, country_csv)\n",
    "\n",
    "# Remove null rows\n",
    "remove_null_rows(country_csv, nonull_cols, nonull_csv)\n",
    "\n",
    "# Update Implementation field\n",
    "update_implementation_field(nonull_csv, upd_impl_csv)\n",
    "\n",
    "# remove rows where\n",
    "# 1. business_name and business_address are same\n",
    "# 2. business_name and contact_business_address are same\n",
    "# 3. business_name and are frn same\n",
    "remove_duplicates_based_on_2_fields(upd_impl_csv, \"business_name\", \"business_address\", dedup_2F_csv)\n",
    "remove_duplicates_based_on_2_fields(dedup_2F_csv, \"business_name\", \"contact_business_address\", dedup_2F_csv)\n",
    "remove_duplicates_based_on_2_fields(dedup_2F_csv, \"business_name\", \"frn\", dedup_2F_csv)\n",
    "\n",
    "# sort rows based on business name\n",
    "sort_by_business_name(dedup_2F_csv, sort_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete final file if it exists and write a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(final_csv):\n",
    "    os.remove(final_csv)\n",
    "os.rename(sort_csv, final_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV stats:\n",
      "Total providers = 7346\n",
      "Full S/S implementation = 4111\n",
      "Partial S/S implementation = 1453\n",
      "No S/S implementation = 1782\n",
      "Count of voice providers = 420\n",
      "Count of gateway providers = 6720\n",
      "Count of intermediate providers = 681\n"
     ]
    }
   ],
   "source": [
    "print_stats(final_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
